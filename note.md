

# ~4.13

## 日志

目前主要是依照pdf上的知识点，结合李航老师的统计学习方法和周志华老师的机器学习在学。

到目前为止，学了机器学习的历史、模型评估方法。机器学习模型学了KNN、决策树、朴素贝叶斯、对率回归、SVM(还没学完)。

对于一些机器学习模型中复杂的数学推导，暂时先跳过了。



## 1. 历史

1980：符号主义（决策树，），连接主义（神经网络，），统计学习（SVM，），深度学习（多层神经网络，）

## 2. 模型评估

1. 评估方法

   * 留出法
   * 交叉验证法
   * 自助法

2. 性能度量

   错误率和精度是**分类**任务种最常用的性能度量，均方误差是**回归**任务中最常用的性能度量

   错误率与精度常用但不满足所用任务要求

   * 查准率precision
   * 查全率recall,与前者往往不能兼得
   * f1为前两个的调和平均，MACRO-F1,MICRO-F1
   * ROC,AUC

3. 比较检验

## KNN

* 优点：精度高，对异常值不敏感

* 缺点：计算复杂度高

* 使用数据范围：数值型和标称型

* 三要素：

  * 距离度量

  * K值选择

    小，过拟合，模型复杂；大，模型简单；通常有交叉验证选择

  * 分类决策规则

## 决策树

* 优点：易于理解实现

* 缺点：对于连续性字段难以预测；对于时间顺序的数据需要很多预处理

* 数据型和常规型

* ID3算法：递归选择**信息增益**最大的特征产生分支。

  信息熵表示不确定性，越大不确定性越高

  数据集D的经验熵：
  $$
  H(D)=-\sum_{k=1}^K\frac{|C_k|}{|D|}\log_2\frac{|C_k|}{|D|}
  $$
  |C_k|表示标签为k的数量。

  特征A对数据集D的条件经验熵：
  $$
  H(D|A)=\sum_{i=1}^n\frac{|D_i|}{|D|}H(D_i)
  $$
  |D_i|表示按照特征A分得第i类得数量。实际上是按照特征A分类所得子集的经验熵的带权平均。

  信息增益：
  $$
  g(D,A)=H(D)-H(D|A)
  $$

* 解决过拟合：
  1. <u>正则化</u>?
  2. 剪枝处理
     * 预先剪枝
     * 后剪枝

## 朴素贝叶斯

极大似然法用频率代替概率，学习先验概率和条件概率，的得到后验概率。

在条件独立性假设下，朴素贝叶斯分类器：
$$
y=arg\max_{c_k}P(Y=c_k)\prod_jP(X^{(j)}=x^{(j)}|Y=c_k)
$$
c_k为标签。

## 逻辑回归

逻辑斯谛二项分类模型：
$$
P(Y=1|x)=\frac{\exp(wx)}{1+\exp(wx)}
$$

$$
P(Y=0|x)=\frac{1}{1+\exp(wx)}
$$

模型将线性函数`wx`转化为概率。

使用极大似然法估计模型参数，对数似然函数：
$$
L(w)=\sum_{i=1}^{N}[y_i(wx_i)-\log(1+\exp(wx_i))]
$$

对L（w）求极大值，得到w的估计值。

模型学习转化为以对数似然函数为目标函数的最优化问题，通常采用梯度下降法或牛顿法等

## 支持向量机（SVM）

二分类模型

由简单到复杂分为：1.线性可分支持向量机；2.线性支持向量机；3.非线性支持向量机

对于线性可分，通过硬间隔最大化来学习；近似线性可分时，通过软间隔最大化来学习；线性不可分时，使用核技巧和软间隔最大化学习。

### 线性可分

利用误分类最小策略求的超平面无穷多个，但是间隔最大的超平面唯一。超平面为
$$
w^*x+b^*=0
$$
**函数间隔**，表示分类的正确性和置信度：
$$
\hat\gamma_i=y_i(wx_i+b)
$$
考虑到和w、b的大小有关，改进为**几何间隔**，其中||w||表示L2范数，即平方和再开方
$$
\gamma_i=y_i(\frac{wx_i}{||w||}+\frac{b}{||w||})
$$
超平面对训练集T的几何间隔为gamma_i的最小值：
$$
\gamma=\min_{i=1,,n}\gamma_i
$$
间隔最大化意味着充分高的确信度对数据分类。

最终转化为一个<u>凸二次规划？</u>问题:
$$
\min_{w,b}\frac{1}{2}||w|| ^2 
$$

$$
s.t. y_i(wx_i+b)-1>=0,i=1,2...N
$$



***

